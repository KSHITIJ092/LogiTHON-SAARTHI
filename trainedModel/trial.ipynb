{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            first_name         last_name                     email  \\\n",
      "9254      Michael Webb      Linda Hunter          ylee@example.net   \n",
      "1561    Cynthia Dennis    Cassandra Reed  tracysalinas@example.com   \n",
      "1670       Brian Bryan    Mark Alexander         lhill@example.org   \n",
      "6087     Crystal Brown  Philip Henderson      fmorales@example.net   \n",
      "6669   Mr. John Taylor     Anthony Smith   michaelford@example.org   \n",
      "...                ...               ...                       ...   \n",
      "5734    Danielle Drake    Cassandra Levy        dsingh@example.com   \n",
      "5191    Jaime Crawford    Cheryl Webster    jennifer15@example.org   \n",
      "5390  Christine Arnold       Joshua Hull     michael44@example.net   \n",
      "860   Nicole Velasquez       Brian Young        tina24@example.org   \n",
      "7270      Alan Fischer        Paul Stone  schultzdavid@example.net   \n",
      "\n",
      "      product_id       qty invoice_date                         address  \\\n",
      "9254         174  0.773915   1987-07-31                   164 Brad Ford   \n",
      "1561         151 -1.554700   2009-01-20       4346 Tina Drives Apt. 885   \n",
      "1670         141  0.773915   1978-12-13        1032 Garcia Via Apt. 065   \n",
      "6087         174 -1.554700   1984-03-22             76530 Jackson Wells   \n",
      "6669         189 -0.390392   1973-08-14             80881 Jonathan Pike   \n",
      "...          ...       ...          ...                             ...   \n",
      "5734         196  1.550121   2011-04-02               745 Holland Fords   \n",
      "5191         116  0.385813   1988-09-09  7339 Kimberly Bypass Suite 294   \n",
      "5390         104 -0.002290   1978-12-08                 7162 Weiss Mall   \n",
      "860          176 -0.390392   1995-05-29             2494 Brittany Ranch   \n",
      "7270         161  1.162018   1975-04-15                2362 Blake Cliff   \n",
      "\n",
      "                   city  stock_code                       job  \n",
      "9254  Port Heatherburgh    10950395       Magazine journalist  \n",
      "1561      Victoriaburgh    59205074           Games developer  \n",
      "1670        Ramirezland    55176422              Bonds trader  \n",
      "6087         Holmesport    38123658              Metallurgist  \n",
      "6669         Lauramouth    54860650            Office manager  \n",
      "...                 ...         ...                       ...  \n",
      "5734        Port Joanna    86270205                     Actor  \n",
      "5191   West Zacharystad    61538696  Magazine features editor  \n",
      "5390       Port Brianna    86923828             Administrator  \n",
      "860        Burkeborough    64672267  Therapist, horticultural  \n",
      "7270        Gabrielstad    40182629        Secretary, company  \n",
      "\n",
      "[8000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('invoices.csv')  # Update 'invoices.csv' with the actual filename\n",
    "df['invoice_date'] = pd.to_datetime(df['invoice_date'], format=r'%d/%m/%Y')\n",
    "\n",
    "# 1. Handling Missing Values\n",
    "df.dropna(inplace=True)  # Drop rows with any missing values, you can customize this based on your requirement\n",
    "\n",
    "# 2. Data Type Conversion\n",
    "df['invoice_date'] = pd.to_datetime(df['invoice_date'])  # Convert 'invoice_date' column to datetime\n",
    "\n",
    "# 3. Removing Duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 4. Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['qty', 'amount']  # Assuming these are numerical columns needing scaling\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# 5. Encoding Categorical Variables\n",
    "# This step depends on the specific requirements and algorithms being used. \n",
    "# You can use techniques like one-hot encoding or label encoding here.\n",
    "\n",
    "# 6. Feature Engineering\n",
    "# Not applied here as it depends on the specific requirements and available data.\n",
    "\n",
    "# 7. Handling Outliers\n",
    "# Not applied here as it depends on the specific requirements and algorithms being used.\n",
    "\n",
    "# 8. Data Scaling\n",
    "# Not applied here as it depends on the specific requirements and algorithms being used.\n",
    "\n",
    "# 9. Data Splitting\n",
    "# Split the dataset into features (X) and target variable (y) if you're building a predictive model\n",
    "# Replace 'amount' with the actual name of your target column\n",
    "X = df.drop('amount', axis=1)\n",
    "y = df['qty']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 10. Feature Selection\n",
    "# Not applied here as it depends on the specific requirements and algorithms being used.\n",
    "\n",
    "# Display the preprocessed dataframe\n",
    "# print(df.head(50))\n",
    "print(X_train)  # Displaying X_train to verify the split\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
